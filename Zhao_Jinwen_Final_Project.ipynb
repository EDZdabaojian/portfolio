{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96f75ab5-17d0-4000-8e0a-d8e9e88796b2",
   "metadata": {},
   "source": [
    "<center><h1>Final Project</h1></center>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543cba05-fa2d-4988-8a71-0a2b818986f3",
   "metadata": {},
   "source": [
    "Name: Jinwen \"Eddie\" Zhao\n",
    "<br>\n",
    "Github Username: jinwenz2024\n",
    "<br>\n",
    "USC ID: 7666343953"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c68f70a-01a2-4e8b-95f7-e7eae1a86602",
   "metadata": {},
   "source": [
    "## 1. Text Classification\n",
    "\n",
    "It is highly recommended that you complete this project using Keras and Python.\n",
    "\n",
    "### (a)\n",
    "In this problem, we are trying to build a classifier to analyze the sentiment of\n",
    "reviews. You are provided with text data in two folders: one folder involves\n",
    "positive reviews, and one folder involves negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72afb797-5591-4c43-a84f-231e6b71ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.io. Tokenizer API, pad_sequences\n",
    "# Tensorflow: https://www.tensorflow.org/\n",
    "# Install Keras and tensorflow\n",
    "# pip install keras\n",
    "# pip install tensorflow\n",
    "# pip install -q --upgrade keras-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c074b878-4bbe-440d-98cf-d5c4a3b2cd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import keras\n",
    "#import keras_nlp\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import glob\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump, load\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Flatten, Dense, Dropout, Conv1D, MaxPooling1D, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ae4d99-ca8d-467b-98ce-9ab123e78cd2",
   "metadata": {},
   "source": [
    "### Data Exploration and Pre-processing\n",
    "i. You can use binary encoding for the sentiments , i.e y = 1 for positive senti\u0002ments and y = −1 for negative sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceb0894-74a9-4b61-9921-3e0a14548069",
   "metadata": {},
   "source": [
    "ii. The data are pretty clean. Remove the punctuation and numbers from the\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78cb2a13-717e-4c92-91b3-c0dd8e18c421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning by removing numbers and puntuations.\n",
    "def clean_txt(text):    # Assisted by ChatGPT\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuations\n",
    "    text = text.replace('\\n', ' ')  # Replace newlines\n",
    "    text = re.sub(r'\\d+', '', text)   # Remove numbers\n",
    "    text = ' '.join(text.split())  # Remove leading, trailing, and extra spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfbdbaf-7917-430d-b9f3-2dd0512ed6cc",
   "metadata": {},
   "source": [
    "iii. The name of each text file starts with cv number. Use text files 0-699 in each\n",
    "class for training and 700-999 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "486bd12c-ef1d-4201-b3e4-95da8aabc8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the texts from both pos and neg folders\n",
    "pos_train_path = '../data/pos/train'\n",
    "pos_test_path = '../data/pos/test'\n",
    "neg_train_path = '../data/neg/train'\n",
    "neg_test_path = '../data/neg/test'\n",
    "\n",
    "# Use text files 0-699 in each class for training and 700-999 for testing. The train/test files are already seperated in different folders.\n",
    "\n",
    "# Read all txt files in a given folder (Assisted by ChatGPT)\n",
    "def read_txt(folder_path):\n",
    "    txt_list = []\n",
    "    txt_files = glob.glob(os.path.join(folder_path, '*.txt'))\n",
    "    for file_path in txt_files:\n",
    "        with open(file_path, 'r') as file:\n",
    "            text = file.read()\n",
    "            cleaned_text = clean_txt(text)\n",
    "            txt_list.append(cleaned_text)\n",
    "    return txt_list\n",
    "\n",
    "pos_train = read_txt(pos_train_path)\n",
    "pos_test = read_txt(pos_test_path)\n",
    "neg_train = read_txt(neg_train_path)\n",
    "neg_test = read_txt(neg_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990f7e35-9ead-43aa-9e30-f6ad029fbac9",
   "metadata": {},
   "source": [
    "iv. Count the number of unique words in the whole dataset (train + test) and\n",
    "print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a1a9bf-597f-4369-9be7-a83b412af4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pos_train + neg_train\n",
    "y_train = [1 for i in range(len(pos_train))] + [0 for i in range(len(neg_train))]  # 1: positive   0: negative\n",
    "X_test = pos_test + neg_test\n",
    "y_test = [1 for i in range(len(pos_test))] + [0 for i in range(len(neg_test))]\n",
    "\n",
    "df_train = pd.DataFrame({\n",
    "    'text': pos_train + neg_train,\n",
    "    'mood': [1 for i in range(len(pos_train))] + [0 for i in range(len(neg_train))]  # 1: positive   0: negative\n",
    "})\n",
    "df_test = pd.DataFrame({\n",
    "    'text': pos_test + neg_test,\n",
    "    'mood': [1 for i in range(len(pos_test))] + [0 for i in range(len(neg_test))]\n",
    "})\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "X = df['text']\n",
    "y = df['mood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ca7078c-1286-477b-82d4-d403dade487b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count (show first 15):\n",
      "[('films', 2103), ('adapted', 45), ('from', 4986), ('comic', 375), ('books', 81), ('have', 4899), ('had', 1544), ('plenty', 129), ('of', 33971), ('success', 216), ('whether', 216), ('theyre', 414), ('about', 3518), ('superheroes', 12), ('batman', 195)]\n",
      "\n",
      "Number of unique words: 46830\n"
     ]
    }
   ],
   "source": [
    "# Create tokenizer (from the snippet of code given in the final project)\n",
    "t = Tokenizer()\n",
    "\n",
    "# Fit the tokenizers on the documents\n",
    "t.fit_on_texts(X)   # Takes in a list of strings\n",
    "\n",
    "# Summarize what was learned\n",
    "print('Word count (show first 15):')\n",
    "unique_word_count = t.word_counts\n",
    "print(list(unique_word_count.items())[:15]) # \"OrderedDict([('films', 2103), ('adapted', 45), ('from', 4986), ('comic', 375), ('books', 81), ('have', 4899), ('had', 1544), ('plenty', 129), ('of', 33971), ('success', 216), ('whether', 216), ('theyre', 414), ('about', 3518), ('superheroes', 12), ('batman', 195), ('superman', 23), ('spawn', 75), ...\")\n",
    "print('\\nNumber of unique words:', len(unique_word_count)) \n",
    "\n",
    "#print('Document count:', t.document_count)\n",
    "#print('Word Index:', t.word_index)\n",
    "#print('Word_docs:', word_docs)\n",
    "\n",
    "# Integer encode documents\n",
    "#encoded_docs = t.text_to_matrix(X, mode = 'count')\n",
    "#print('\\nEncoded Document:', encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2046f01-0e95-48ab-88c3-96609b5e3445",
   "metadata": {},
   "source": [
    "v. Calculate the average review length and the standard deviation of review\n",
    "lengths. Report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfc8515d-b4d4-4438-bce5-cdb1d3cddf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average review length (in terms of character counts): 644.3555\n",
      "Standard deviation of review length: 284.97987142910637\n"
     ]
    }
   ],
   "source": [
    "file_len_list = []\n",
    "for file in X:\n",
    "    #file_len_list.append(len(file))    # Append the character count\n",
    "    file_len_list.append(len(file.split()))  # Append the word count per file\n",
    "print('Average review length (in terms of character counts):', np.mean(file_len_list))\n",
    "print('Standard deviation of review length:', np.std(file_len_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd91de52-543f-49e5-8786-5f741248a6f1",
   "metadata": {},
   "source": [
    "vi. Plot the histogram of review lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "581f765c-d603-430c-99da-b59e25cb72b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1IAAAFzCAYAAAA0STi9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABCOUlEQVR4nO3df3zP9f7/8fub/TLN2JbNjk2LkRCSFAr5lZofOefQ8SPhFIfyaxLHJ41TWziWUpJzHJskdQon6mCKIfphSJgJy5a2dqbZjNlme33/6OL97d1Me8377f3edrteLu/Lxev5ej5f78dLr8bd8/V6viyGYRgCAAAAAFRYLWcXAAAAAABVDUEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACT3JxdgCsoLS3VDz/8IB8fH1ksFmeXAwAAAMBJDMPQ+fPnFRwcrFq1yp93IkhJ+uGHHxQSEuLsMgAAAAC4iPT0dDVu3Ljc/QQpST4+PpJ+/s2qV6+ek6sBAAAA4Cx5eXkKCQmxZoTyEKQk6+189erVI0gBAAAA+M1HflhsAgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJbs4uAIDzpKWlKTs72/S4gIAAhYaGOqAiAACAqsGpQWrnzp1auHChkpKSlJGRofXr12vQoEE2fZKTk/Xss88qMTFRpaWlatWqld577z3rX+IKCws1ffp0vfPOOyooKFDPnj21dOlSNW7c2AlnBFQdaWlpanFbS10quGh6rFcdb6UcSyZMAQCAGsupQerChQtq27atRo8erd///vdl9p88eVJdu3bV2LFjNXfuXPn6+io5OVleXl7WPlOmTNHGjRu1du1a+fv7KzIyUhEREUpKSlLt2rVv5OkAVUp2drYuFVyUf0Sk3P1DKjyu+Gy6zm5apOzsbIIUAACosZwapPr166d+/fqVu3/27Nl66KGHtGDBAmvbrbfeav11bm6uVqxYobfeeku9evWSJK1evVohISHatm2b+vbt67jigWrC3T9EnkHNnF0GAABAleKyi02Ulpbqo48+UvPmzdW3b181bNhQnTp10oYNG6x9kpKSVFxcrD59+ljbgoOD1bp1a+3Zs6fcYxcWFiovL8/mAwAAAAAV5bJBKisrS/n5+XrppZf04IMPauvWrXrkkUc0ePBgJSYmSpIyMzPl4eGhBg0a2IwNDAxUZmZmuceOiYmRr6+v9RMSUvHbmgAAAADAZYNUaWmpJGngwIGaOnWq2rVrp5kzZyoiIkLLli275ljDMGSxWMrdP2vWLOXm5lo/6enpdq0dAAAAQPXmskEqICBAbm5uuv32223aW7ZsqbS0NElSUFCQioqKlJOTY9MnKytLgYGB5R7b09NT9erVs/kAAAAAQEW57HukPDw81LFjR6WkpNi0Hz9+XE2aNJEkdejQQe7u7kpISNCQIUMkSRkZGTp8+LDNAhVAdVeZ90ElJyc7qBoAAIDqz6lBKj8/XydOnLBup6am6uDBg/Lz81NoaKieeeYZDR06VPfff7969OihzZs3a+PGjdqxY4ckydfXV2PHjlVkZKT8/f3l5+en6dOnq02bNtZV/IDq7nreBwUAAIDKcWqQ2rdvn3r06GHdnjZtmiRp1KhRiouL0yOPPKJly5YpJiZGkyZNUosWLfTBBx+oa9eu1jEvv/yy3NzcNGTIEOsLeePi4niHFGqMyr4PquDUPuXuWu3AygAAAKovpwap7t27yzCMa/YZM2aMxowZU+5+Ly8vLVmyREuWLLF3eUCVYvZ9UMVnWWQFAACgslx2sQkAAAAAcFUEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJjksi/kBWoiXqwLAABQNRCkABfBi3UBAACqDoIU4CJ4sS4AAEDVQZACXAwv1gUAAHB9LDYBAAAAACYRpAAAAADAJIIUAAAAAJjEM1IAbpjKLO8uSQEBAQoNDXVARQAAAJVDkAJwQ1zP8u5edbyVciyZMAUAAFwGQQrADVHZ5d2Lz6br7KZFys7OJkgBAACXQZACcEOZXd4dAADAFbHYBAAAAACYRJACAAAAAJMIUgAAAABgEs9IAQ5QmWW+k5OTHVSNY5itt6qdHwAAwLUQpAA7u55lvquCkvwcyWLRiBEjnF0KAACA0xCkADur7DLfBaf2KXfXagdWZh+lhfmSYVTb8wMAAKgIghTgIGaX+S4+m+7Aauyvup8fAADAtbDYBAAAAACYRJACAAAAAJOcGqR27typ/v37Kzg4WBaLRRs2bCi377hx42SxWLR48WKb9sLCQj399NMKCAhQ3bp1NWDAAH3//feOLRwAAABAjebUIHXhwgW1bdtWr7322jX7bdiwQV988YWCg4PL7JsyZYrWr1+vtWvXavfu3crPz1dERIRKSkocVTYAAACAGs6pi03069dP/fr1u2afM2fO6KmnntKWLVv08MMP2+zLzc3VihUr9NZbb6lXr16SpNWrVyskJETbtm1T3759HVY7AAAAgJrLpZ+RKi0t1ciRI/XMM8+oVatWZfYnJSWpuLhYffr0sbYFBwerdevW2rNnT7nHLSwsVF5ens0HAAAAACrKpYPU/Pnz5ebmpkmTJl11f2Zmpjw8PNSgQQOb9sDAQGVmZpZ73JiYGPn6+lo/ISEVfxcOAAAAALhskEpKStIrr7yiuLg4WSwWU2MNw7jmmFmzZik3N9f6SU/n/TYAAAAAKs5lg9SuXbuUlZWl0NBQubm5yc3NTadPn1ZkZKRuueUWSVJQUJCKioqUk5NjMzYrK0uBgYHlHtvT01P16tWz+QAAAABARblskBo5cqQOHTqkgwcPWj/BwcF65plntGXLFklShw4d5O7uroSEBOu4jIwMHT58WJ07d3ZW6QAAAACqOaeu2pefn68TJ05Yt1NTU3Xw4EH5+fkpNDRU/v7+Nv3d3d0VFBSkFi1aSJJ8fX01duxYRUZGyt/fX35+fpo+fbratGljXcUPAAAAAOzNqUFq37596tGjh3V72rRpkqRRo0YpLi6uQsd4+eWX5ebmpiFDhqigoEA9e/ZUXFycateu7YiSAQAAAMC5Qap79+4yDKPC/b/77rsybV5eXlqyZImWLFlix8oAAAAAoHwu+4wUAAAAALgqghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGCSm7MLAICKSE5ONj0mICBAoaGhDqgGAADUdAQpAC6tJD9Hslg0YsQI02O96ngr5VgyYQoAANgdQQqASystzJcMQ/4RkXL3D6nwuOKz6Tq7aZGys7MJUgAAwO4IUgCqBHf/EHkGNXN2GQAAAJJYbAIAAAAATDMdpAoKCnTx4kXr9unTp7V48WJt3brVroUBAAAAgKsyHaQGDhyoVatWSZLOnTunTp06adGiRRo4cKDeeOMNuxcIAAAAAK7GdJDav3+/7rvvPknS+++/r8DAQJ0+fVqrVq3Sq6++avcCAQAAAMDVmA5SFy9elI+PjyRp69atGjx4sGrVqqV77rlHp0+ftnuBAAAAAOBqTAepZs2aacOGDUpPT9eWLVvUp08fSVJWVpbq1atn9wIBAAAAwNWYDlJz5szR9OnTdcstt6hTp0669957Jf08O9W+fXu7FwgAAAAArsb0e6T+8Ic/qGvXrsrIyFDbtm2t7T179tTgwYPtWhwAAAAAuCLTM1JjxoxR3bp11b59e9Wq9f+Ht2rVSvPnz7drcQAAAADgikwHqfj4eBUUFJRpLygosC6LXlE7d+5U//79FRwcLIvFog0bNlj3FRcX69lnn1WbNm1Ut25dBQcH67HHHtMPP/xgc4zCwkI9/fTTCggIUN26dTVgwAB9//33Zk8LAAAAACqswkEqLy9Pubm5MgxD58+fV15envWTk5Ojjz/+WA0bNjT15RcuXFDbtm312muvldl38eJF7d+/X88995z279+vdevW6fjx4xowYIBNvylTpmj9+vVau3atdu/erfz8fEVERKikpMRULQAAAABQURV+Rqp+/fqyWCyyWCxq3rx5mf0Wi0Vz58419eX9+vVTv379rrrP19dXCQkJNm1LlizR3XffrbS0NIWGhio3N1crVqzQW2+9pV69ekmSVq9erZCQEG3btk19+/Y1VQ8AAAAAVESFg9T27dtlGIYeeOABffDBB/Lz87Pu8/DwUJMmTRQcHOyQIq/Izc2VxWJR/fr1JUlJSUkqLi62LsEuScHBwWrdurX27NlTbpAqLCxUYWGhdTsvL8+hdQMAAACoXiocpLp16yZJSk1NVUhIiM1CEzfCpUuXNHPmTA0bNsz6vqrMzEx5eHioQYMGNn0DAwOVmZlZ7rFiYmJMz54BAAAAwBWmlz9v0qSJzp07py+//FJZWVkqLS212f/YY4/ZrbgriouL9eijj6q0tFRLly79zf6GYchisZS7f9asWZo2bZp1Oy8vTyEhIXapFQAAAED1ZzpIbdy4UcOHD9eFCxfk4+NjE1gsFovdg1RxcbGGDBmi1NRUffrpp9bZKEkKCgpSUVGRcnJybGalsrKy1Llz53KP6enpKU9PT7vWCQAAAKDmMH1/XmRkpMaMGaPz58/r3LlzysnJsX5++uknuxZ3JUR9++232rZtm/z9/W32d+jQQe7u7jaLUmRkZOjw4cPXDFIAAAAAcD1Mz0idOXNGkyZNkre393V/eX5+vk6cOGHdTk1N1cGDB+Xn56fg4GD94Q9/0P79+7Vp0yaVlJRYn3vy8/OTh4eHfH19NXbsWEVGRsrf319+fn6aPn262rRpY13FDwAAAADszXSQ6tu3r/bt26dbb731ur9837596tGjh3X7ynNLo0aNUlRUlD788ENJUrt27WzGbd++Xd27d5ckvfzyy3Jzc9OQIUNUUFCgnj17Ki4uTrVr177u+gAAAADgakwHqYcffljPPPOMjh49qjZt2sjd3d1m/69fmHst3bt3l2EY5e6/1r4rvLy8tGTJEi1ZsqTC3wsAAAAA18N0kHriiSckSfPmzSuzz2KxqKSk5PqrAgAAAAAXZjpI/Xq5cwAAAACoaa7rrbqXLl2yVx0AAAAAUGWYnpEqKSlRdHS0li1bph9//FHHjx/Xrbfequeee0633HKLxo4d64g6AaBSkpOTKzUuICBAoaGhdq4GAABUF6aD1Isvvqj4+HgtWLDA+ryUJLVp00Yvv/wyQQqASyjJz5EsFo0YMaJS473qeCvlWDJhCgAAXJXpILVq1SotX75cPXv21Pjx463td9xxh44dO2bX4gCgskoL8yXDkH9EpNz9Q0yNLT6brrObFik7O5sgBQAArqpSL+Rt1qxZmfbS0lIVFxfbpSgAsBd3/xB5BpX9mQUAAHA9TC820apVK+3atatM+7///W+1b9/eLkUBAAAAgCszPSP1/PPPa+TIkTpz5oxKS0u1bt06paSkaNWqVdq0aZMjagQAAAAAl2J6Rqp///5699139fHHH8tisWjOnDlKTk7Wxo0b1bt3b0fUCAAAAAAuxfSMlCT17dtXffv2tXctAAAAAFAlVCpIXZGfn6/S0lKbtnr16l1XQQAAAADg6kzf2peamqqHH35YdevWla+vrxo0aKAGDRqofv36atCggSNqBAAAAACXYnpGavjw4ZKkf/3rXwoMDJTFYrF7UQAAAADgykwHqUOHDikpKUktWrRwRD0AAAAA4PJM39rXsWNHpaenO6IWAAAAAKgSTM9I/fOf/9T48eN15swZtW7dWu7u7jb777jjDrsVBwAAAACuyHSQ+t///qeTJ09q9OjR1jaLxSLDMGSxWFRSUmLXAgEAAADA1ZgOUmPGjFH79u31zjvvsNgEgGotOTnZ9JiAgACFhoY6oBoAAOBKTAep06dP68MPP1SzZs0cUQ8AOF1Jfo5ksWjEiBGmx3rV8VbKsWTCFAAA1ZzpIPXAAw/o66+/JkgBqLZKC/Mlw5B/RKTc/UMqPK74bLrOblqk7OxsghQAANWc6SDVv39/TZ06Vd98843atGlTZrGJAQMG2K04AHAmd/8QeQbxj0YAAKAs00Fq/PjxkqR58+aV2cdiEwAAAABqAtNBqrS01BF1AAAAAECVYfqFvAAAAABQ05mekbraLX2/NGfOnAofa+fOnVq4cKGSkpKUkZGh9evXa9CgQdb9hmFo7ty5Wr58uXJyctSpUye9/vrratWqlbVPYWGhpk+frnfeeUcFBQXq2bOnli5dqsaNG5s9NQAAAACoENNBav369TbbxcXFSk1NlZubm5o2bWoqSF24cEFt27bV6NGj9fvf/77M/gULFig2NlZxcXFq3ry5XnjhBfXu3VspKSny8fGRJE2ZMkUbN27U2rVr5e/vr8jISEVERCgpKUm1a9c2e3oAAAAA8JtMB6kDBw6UacvLy9Pjjz+uRx55xNSx+vXrp379+l11n2EYWrx4sWbPnq3BgwdLkuLj4xUYGKg1a9Zo3Lhxys3N1YoVK/TWW2+pV69ekqTVq1crJCRE27ZtU9++fU2eHQAAAAD8Nrs8I1WvXj3NmzdPzz33nD0OJ0lKTU1VZmam+vTpY23z9PRUt27dtGfPHklSUlKSiouLbfoEBwerdevW1j4AAAAAYG+mZ6TKc+7cOeXm5trrcMrMzJQkBQYG2rQHBgbq9OnT1j4eHh5q0KBBmT5Xxl9NYWGhCgsLrdt5eXn2KhsAAABADWA6SL366qs224ZhKCMjQ2+99ZYefPBBuxV2hcViKfN9v277td/qExMTo7lz59qlPgAAAAA1j+kg9fLLL9ts16pVSzfffLNGjRqlWbNm2a2woKAgST/POjVq1MjanpWVZZ2lCgoKUlFRkXJycmxmpbKystS5c+dyjz1r1ixNmzbNup2Xl6eQkBC71Q4AAACgejMdpFJTUx1RRxlhYWEKCgpSQkKC2rdvL0kqKipSYmKi5s+fL0nq0KGD3N3dlZCQoCFDhkiSMjIydPjwYS1YsKDcY3t6esrT09PxJwEAAACgWjIdpHJzc1VSUiI/Pz+b9p9++klubm6qV69ehY+Vn5+vEydOWLdTU1N18OBB+fn5KTQ0VFOmTFF0dLTCw8MVHh6u6OhoeXt7a9iwYZIkX19fjR07VpGRkfL395efn5+mT5+uNm3aWFfxAwAAAAB7Mx2kHn30UfXv318TJkywaX/vvff04Ycf6uOPP67wsfbt26cePXpYt6/cbjdq1CjFxcVpxowZKigo0IQJE6wv5N26dav1HVLSz7caurm5aciQIdYX8sbFxfEOKQAAAAAOYzpIffHFF4qNjS3T3r17d82ePdvUsbp37y7DMMrdb7FYFBUVpaioqHL7eHl5acmSJVqyZImp7wYAAACAyjL9HqnCwkJdvny5THtxcbEKCgrsUhQAAAAAuDLTQapjx45avnx5mfZly5apQ4cOdikKAAAAAFyZ6Vv7XnzxRfXq1Utff/21evbsKUn65JNP9NVXX2nr1q12LxAAAAAAXI3pGakuXbpo7969aty4sd577z1t3LhRzZo106FDh3Tfffc5okYAAAAAcCmmZ6QkqV27dlqzZo29awEAAACAKqFSQaqkpEQbNmxQcnKyLBaLbr/9dg0YMIAlxwEAAADUCKaD1IkTJ/Twww/r+++/V4sWLWQYho4fP66QkBB99NFHatq0qSPqBAAAAACXYfoZqUmTJunWW29Venq69u/frwMHDigtLU1hYWGaNGmSI2oEAAAAAJdiekYqMTFRn3/+ufz8/Kxt/v7+eumll9SlSxe7FgcAAAAArsj0jJSnp6fOnz9fpj0/P18eHh52KQoAAAAAXJnpIBUREaEnn3xSX3zxhQzDkGEY+vzzzzV+/HgNGDDAETUCAAAAgEsxHaReffVVNW3aVPfee6+8vLzk5eWlLl26qFmzZnrllVccUSMAAAAAuBTTz0jVr19f//nPf/Ttt9/q2LFjMgxDt99+u5o1a+aI+gAAAADA5VTqPVKSFB4ervDwcHvWAgAAAABVQoWC1LRp0yp8wNjY2EoXAwAAAABVQYWC1IEDB2y2k5KSVFJSohYtWkiSjh8/rtq1a6tDhw72rxAAAAAAXEyFgtT27dutv46NjZWPj4/i4+PVoEEDSVJOTo5Gjx6t++67zzFVAgAAAIALMb1q36JFixQTE2MNUZLUoEEDvfDCC1q0aJFdiwMAAAAAV2Q6SOXl5enHH38s056VlXXVF/UCAAAAQHVjOkg98sgjGj16tN5//319//33+v777/X+++9r7NixGjx4sCNqBAAAAACXYnr582XLlmn69OkaMWKEiouLfz6Im5vGjh2rhQsX2r1AAAAAAHA1poOUt7e3li5dqoULF+rkyZMyDEPNmjVT3bp1HVEfAAAAALicSr+Qt27durrjjjvsWQvgctLS0pSdnW1qTHJysoOqAQAAgKuodJACqru0tDS1uK2lLhVcdHYpAAAAcDEEKaAc2dnZulRwUf4RkXL3D6nwuIJT+5S7a7UDKwMAAICzEaSA3+DuHyLPoGYV7l98Nt2B1QAAAMAVVGj58zvvvFM5OTmSpHnz5unixRtzq9Ply5f1f//3fwoLC1OdOnV06623at68eSotLbX2MQxDUVFRCg4OVp06ddS9e3cdOXLkhtQHAAAAoGaq0IxUcnKyLly4oAYNGmju3LkaP368vL29HV2b5s+fr2XLlik+Pl6tWrXSvn37NHr0aPn6+mry5MmSpAULFig2NlZxcXFq3ry5XnjhBfXu3VspKSny8fFxeI24sSqz+IMkBQQEKDQ01AEVAQAAoCaqUJBq166dRo8era5du8owDP3973/XTTfddNW+c+bMsVtxe/fu1cCBA/Xwww9Lkm655Ra988472rdvn6SfZ6MWL16s2bNnW18GHB8fr8DAQK1Zs0bjxo2zWy1wvutZ/MGrjrdSjiUTpgAAAGAXFQpScXFxev7557Vp0yZZLBb997//lZtb2aEWi8WuQapr165atmyZjh8/rubNm+vrr7/W7t27tXjxYklSamqqMjMz1adPH+sYT09PdevWTXv27Ck3SBUWFqqwsNC6nZeXZ7ea4TiVXfyh+Gy6zm5apOzsbIIUAAAA7KJCQapFixZau3atJKlWrVr65JNP1LBhQ4cWJknPPvuscnNzddttt6l27doqKSnRiy++qD/96U+SpMzMTElSYGCgzbjAwECdPn263OPGxMRo7ty5jiscDmV28QcAAADA3iq02MQvlZaW3pAQJUnvvvuuVq9erTVr1mj//v2Kj4/X3//+d8XHx9v0s1gsNtuGYZRp+6VZs2YpNzfX+klPZ5U1AAAAABVXqeXPT548qcWLFys5OVkWi0UtW7bU5MmT1bRpU7sW98wzz2jmzJl69NFHJUlt2rTR6dOnFRMTo1GjRikoKEjSzzNTjRo1so7LysoqM0v1S56envL09LRrrQBwRXJysukxLIgCAEDVYjpIbdmyRQMGDFC7du3UpUsXGYahPXv2qFWrVtq4caN69+5tt+IuXryoWrVsJ81q165tXf48LCxMQUFBSkhIUPv27SVJRUVFSkxM1Pz58+1WBwBUREl+jmSxaMSIEabHsiAKAABVi+kgNXPmTE2dOlUvvfRSmfZnn33WrkGqf//+evHFFxUaGqpWrVrpwIEDio2N1ZgxYyT9fEvflClTFB0drfDwcIWHhys6Olre3t4aNmyY3eoAgIooLcyXDIMFUQAAqAFMB6nk5GS99957ZdrHjBljXU3PXpYsWaLnnntOEyZMUFZWloKDgzVu3DiblQFnzJihgoICTZgwQTk5OerUqZO2bt3KO6QAOA0LogAAUP2ZDlI333yzDh48qPDwcJv2gwcP2n0RCh8fHy1evPiaAc1isSgqKkpRUVF2/W4AAAAAKI/pIPXEE0/oySef1KlTp9S5c2dZLBbt3r1b8+fPV2RkpCNqBAAAAACXYjpIPffcc/Lx8dGiRYs0a9YsSVJwcLCioqI0adIkuxcIAAAAAK7GdJCyWCyaOnWqpk6dqvPnz0sSzyMBAAAAqFEq9R6pKwhQqErMvtunMu8CAgAAQM1wXUEKqAqu590+AAAAwNUQpFDtVfbdPgWn9il312oHVgYAAICqiiCFGsPsu32Kz6Y7sBoAAABUZbXMdC4uLlaPHj10/PhxR9UDAAAAAC7PVJByd3fX4cOHZbFYHFUPAAAAALg8U0FKkh577DGtWLHCEbUAAAAAQJVg+hmpoqIi/fOf/1RCQoLuuusu1a1b12Z/bGys3YoDAAAAAFdkOkgdPnxYd955pySVeVaKW/4AAAAA1ASmg9T27dsdUQcAAAAAVBmmn5G64sSJE9qyZYsKCgokSYZh2K0oAAAAAHBlpoPU2bNn1bNnTzVv3lwPPfSQMjIyJEl//vOfFRkZafcCAQAAAMDVmL61b+rUqXJ3d1daWppatmxpbR86dKimTp2qRYsW2bVAAKgpkpOTTY8JCAhQaGioA6oBAADXYjpIbd26VVu2bFHjxo1t2sPDw3X69Gm7FQYANUVJfo5ksWjEiBGmx3rV8VbKsWTCFAAAN5jpIHXhwgV5e3uXac/Ozpanp6ddigKAmqS0MF8yDPlHRMrdP6TC44rPpuvspkXKzs4mSAEAcIOZDlL333+/Vq1apb/97W+Sfl7yvLS0VAsXLlSPHj3sXiAA1BTu/iHyDGrm7DIAAEAFmA5SCxcuVPfu3bVv3z4VFRVpxowZOnLkiH766Sd99tlnjqgRAAAAAFyK6VX7br/9dh06dEh33323evfurQsXLmjw4ME6cOCAmjZt6ogaAQAAAMClmJ6RkqSgoCDNnTvX3rUAAAAAQJVQqSCVk5OjFStWKDk5WRaLRS1bttTo0aPl5+dn7/oAAAAAwOWYvrUvMTFRYWFhevXVV5WTk6OffvpJr776qsLCwpSYmOiIGgEAAADApZiekZo4caKGDBmiN954Q7Vr15YklZSUaMKECZo4caIOHz5s9yIBAAAAwJWYnpE6efKkIiMjrSFKkmrXrq1p06bp5MmTdi1Oks6cOaMRI0bI399f3t7eateunZKSkqz7DcNQVFSUgoODVadOHXXv3l1Hjhyxex0AAAAAcIXpIHXnnXcqOTm5THtycrLatWtnj5qscnJy1KVLF7m7u+u///2vjh49qkWLFql+/frWPgsWLFBsbKxee+01ffXVVwoKClLv3r11/vx5u9YCAAAAAFdU6Na+Q4cOWX89adIkTZ48WSdOnNA999wjSfr888/1+uuv66WXXrJrcfPnz1dISIhWrlxpbbvlllusvzYMQ4sXL9bs2bM1ePBgSVJ8fLwCAwO1Zs0ajRs3zq71AAAAAIBUwSDVrl07WSwWGYZhbZsxY0aZfsOGDdPQoUPtVtyHH36ovn376o9//KMSExP1u9/9ThMmTNATTzwhSUpNTVVmZqb69OljHePp6alu3bppz5495QapwsJCFRYWWrfz8vLsVjMAAACA6q9CQSo1NdXRdVzVqVOn9MYbb2jatGn661//qi+//FKTJk2Sp6enHnvsMWVmZkqSAgMDbcYFBgbq9OnT5R43JiaG92ABAAAAqLQKBakmTZo4uo6rKi0t1V133aXo6GhJUvv27XXkyBG98cYbeuyxx6z9LBaLzTjDMMq0/dKsWbM0bdo063ZeXp5CQkLsXD0AAACA6qpSL+Q9c+aMPvvsM2VlZam0tNRm36RJk+xSmCQ1atRIt99+u01by5Yt9cEHH0iSgoKCJEmZmZlq1KiRtU9WVlaZWapf8vT0lKenp93qBAAAAFCzmA5SK1eu1Pjx4+Xh4SF/f3+bmR+LxWLXINWlSxelpKTYtB0/ftw6QxYWFqagoCAlJCSoffv2kqSioiIlJiZq/vz5dqsDAAAAAH7JdJCaM2eO5syZo1mzZqlWLdOrp5sydepUde7cWdHR0RoyZIi+/PJLLV++XMuXL5f0c3CbMmWKoqOjFR4ervDwcEVHR8vb21vDhg1zaG0AAAAAai7TQerixYt69NFHHR6iJKljx45av369Zs2apXnz5iksLEyLFy/W8OHDrX1mzJihgoICTZgwQTk5OerUqZO2bt0qHx8fh9cHAAAAoGYyHaTGjh2rf//735o5c6Yj6ikjIiJCERER5e63WCyKiopSVFTUDakHAAAAAEwHqZiYGEVERGjz5s1q06aN3N3dbfbHxsbarTgAAAAAcEWmg1R0dLS2bNmiFi1aSFKZxSYAAAAAoLozHaRiY2P1r3/9S48//rgDygEAAAAA12d6xQhPT0916dLFEbUAAAAAQJVgOkhNnjxZS5YscUQtAAAAAFAlmL6178svv9Snn36qTZs2qVWrVmUWm1i3bp3digMAAAAAV2Q6SNWvX1+DBw92RC0AAAAAUCWYDlIrV650RB0AgEpKTk42PSYgIEChoaEOqAYAgJrBdJACALiGkvwcyWLRiBEjTI/1quOtlGPJhCkAACrJdJAKCwu75vuiTp06dV0FAQAqprQwXzIM+UdEyt0/pMLjis+m6+ymRcrOziZIAQBQSaaD1JQpU2y2i4uLdeDAAW3evFnPPPOMveoCAFSQu3+IPIOaObsMAABqFNNBavLkyVdtf/3117Vv377rLggAAAAAXJ3p90iVp1+/fvrggw/sdTgAAAAAcFl2C1Lvv/++/Pz87HU4AAAAAHBZpm/ta9++vc1iE4ZhKDMzU//73/+0dOlSuxYHAAAAAK7IdJAaNGiQzXatWrV08803q3v37rrtttvsVRcAAAAAuCzTQer55593RB0AAAAAUGXY7RkpAAAAAKgpKjwjVatWrWu+iFeSLBaLLl++fN1FAQAAAIArq3CQWr9+fbn79uzZoyVLlsgwDLsUBQAAAACurMJBauDAgWXajh07plmzZmnjxo0aPny4/va3v9m1OAAAAABwRZV6RuqHH37QE088oTvuuEOXL1/WwYMHFR8fr9DQUHvXBwAAAAAux1SQys3N1bPPPqtmzZrpyJEj+uSTT7Rx40a1bt3aUfUBAAAAgMup8K19CxYs0Pz58xUUFKR33nnnqrf6ARWRlpam7Oxs0+OSk5MdUA0AAABgXoWD1MyZM1WnTh01a9ZM8fHxio+Pv2q/devW2a04VD9paWlqcVtLXSq46OxSAAAAgEqrcJB67LHHfnP5c0eLiYnRX//6V02ePFmLFy+WJBmGoblz52r58uXKyclRp06d9Prrr6tVq1ZOrRVXl52drUsFF+UfESl3/xBTYwtO7VPurtUOqgwAAACouAoHqbi4OAeW8du++uorLV++XHfccYdN+4IFCxQbG6u4uDg1b95cL7zwgnr37q2UlBT5+Pg4qVr8Fnf/EHkGNTM1pvhsuoOqAQAAAMyp1Kp9N1p+fr6GDx+uf/zjH2rQoIG13TAMLV68WLNnz9bgwYPVunVrxcfH6+LFi1qzZo0TKwYAAABQnVWJIDVx4kQ9/PDD6tWrl017amqqMjMz1adPH2ubp6enunXrpj179pR7vMLCQuXl5dl8AAAAAKCiKnxrn7OsXbtW+/fv11dffVVmX2ZmpiQpMDDQpj0wMFCnT58u95gxMTGaO3eufQsFAAAAUGO49IxUenq6Jk+erNWrV8vLy6vcfr9eBMMwjGsujDFr1izl5uZaP+npPHsDAAAAoOJcekYqKSlJWVlZ6tChg7WtpKREO3fu1GuvvaaUlBRJP89MNWrUyNonKyurzCzVL3l6esrT09NxhQMAAACo1lx6Rqpnz5765ptvdPDgQevnrrvu0vDhw3Xw4EHdeuutCgoKUkJCgnVMUVGREhMT1blzZydWDgAAAKA6c+kZKR8fH7Vu3dqmrW7duvL397e2T5kyRdHR0QoPD1d4eLiio6Pl7e2tYcOGOaNkAAAAADWASwepipgxY4YKCgo0YcIE6wt5t27dyjukAAAAADhMlQtSO3bssNm2WCyKiopSVFSUU+oBAAAAUPO49DNSAAAAAOCKCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAk9ycXQAAwDmSk5NNjwkICFBoaKgDqrGvtLQ0ZWdnmx5XVc4PAOB8BCkAqGFK8nMki0UjRowwPdarjrdSjiW7dNhIS0tTi9ta6lLBRdNjq8L5AQBcA0EKAGqY0sJ8yTDkHxEpd/+QCo8rPpuus5sWKTs726WDRnZ2ti4VXKy25wcAcA0EKQCoodz9Q+QZ1MzZZThMdT8/AIBzsdgEAAAAAJhEkAIAAAAAkwhSAAAAAGASz0gBAFxWZZYxr8yy7gAAmEWQAgC4pOtZxhwAAEcjSAEAXFJllzEvOLVPubtWO7AyAAAIUgAAkypz61xAQECl381kdhnz4rPplfoeAADMIEgBACqkJD9Hslg0YsQI02O96ngr5VgyL7oFAFQbBCkAQIWUFuZLhmH6Vrvis+k6u2mRsrOzCVIAgGqDIAUAMMXsrXYAAFRHBClUGssSAwAAoKYiSKFSWJYYAAAANZlLB6mYmBitW7dOx44dU506ddS5c2fNnz9fLVq0sPYxDENz587V8uXLlZOTo06dOun1119Xq1atnFh59ceyxADMMjsjzQw2AMCVuXSQSkxM1MSJE9WxY0ddvnxZs2fPVp8+fXT06FHVrVtXkrRgwQLFxsYqLi5OzZs31wsvvKDevXsrJSVFPj4+Tj6D6o9liQH8lutZ7Q8AAFfl0kFq8+bNNtsrV65Uw4YNlZSUpPvvv1+GYWjx4sWaPXu2Bg8eLEmKj49XYGCg1qxZo3HjxjmjbADAL1R2tT9msAEArsylg9Sv5ebmSpL8/PwkSampqcrMzFSfPn2sfTw9PdWtWzft2bOHIAUALoQZbABAdVJlgpRhGJo2bZq6du2q1q1bS5IyMzMlSYGBgTZ9AwMDdfr06XKPVVhYqMLCQut2Xl6eAyoGAAAAUF3VcnYBFfXUU0/p0KFDeuedd8rss1gsNtuGYZRp+6WYmBj5+vpaPyEhFb/VBAAAAACqRJB6+umn9eGHH2r79u1q3LixtT0oKEjS/5+ZuiIrK6vMLNUvzZo1S7m5udZPejq3jwAAAACoOJcOUoZh6KmnntK6dev06aefKiwszGZ/WFiYgoKClJCQYG0rKipSYmKiOnfuXO5xPT09Va9ePZsPAAAAAFSUSz8jNXHiRK1Zs0b/+c9/5OPjY5158vX1VZ06dWSxWDRlyhRFR0crPDxc4eHhio6Olre3t4YNG+bk6gEAAABUVy4dpN544w1JUvfu3W3aV65cqccff1ySNGPGDBUUFGjChAnWF/Ju3bqVd0gBAG6YtLQ0ZWdnV2psQECAQkND7VwRAMDRXDpIGYbxm30sFouioqIUFRXl+IIAAPiVtLQ0tbitpS4VXKzUeK863ko5lkyYAoAqxqWDFAAAri47O1uXCi6afuGw9PO7ss5uWqTs7GyCFABUMQQpAADswOwLhwEAVZtLr9oHAAAAAK6IIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwyc3ZBQAAUNMlJyebHlNYWChPT0/T4wICAhQaGmp6HADAFkEKAAAnKcnPkSwWjRgxwvxgSy3JKDU9zKuOt1KOJROmAOA6EaQAAHCS0sJ8yTDkHxEpd/+QCo8rOLVPubtWmx5XfDZdZzctUnZ2NkEKAK4TQQoAgF8we5tdZW7L+zV3/xB5BjWrcP/is+mVGndFZWrmlkAAsEWQAgBA13mbXRVxPefILYEAYIsgBQCArv82u6qgsud4PbcEpqWlKTs722ypzIABcHkEKQAAfqGyt9lVJZW9JdCstLQ0tbitpS4VXDQ9lhkwAK6OIIVK/WuhPZ4JAABUb9nZ2bpUcJFFMQBUSwSpGu56/rUQAICKuFEzYABwIxGkarjK/mthVXomAABgH85Y0dAsnskCcKMQpCCpZjwTAACoHGetaGg2iGVkZOj3f/ijCi8VmP6uqvJMVmWDokRYBOyNIAUAAK7pRq9oeL3Brbo+k3W9t+NXlbAIVBUEKQAAUCE36u6F6w1uN/KZrBt5K2Flb8eX/n9Y3LVrl1q2bGlqLDNZwNURpAAAgEty9dvOnbW8e2WCIi9jBuyPIFWNsIw5AACVV5nFNK5neXezs0PX82e2M17GDFR31SZILV26VAsXLlRGRoZatWqlxYsX67777nN2WTcMy5gDAFA51/tMltkZImct3iGxFD1gT9UiSL377ruaMmWKli5dqi5duujNN99Uv379dPTo0Sr5ryeVnVliGXMAAMy70Ytp3Ojvs4fKzIbxbJV9VfZ5vMLCQnl6epoedz3//WrKawiqRZCKjY3V2LFj9ec//1mStHjxYm3ZskVvvPGGYmJinFydOdc7s+Tq95MDAOCqbvSfoVXhz2yerXIN1/X3Q0stySg1Payy//2c9eygM1T5IFVUVKSkpCTNnDnTpr1Pnz7as2fPVccUFhaqsLDQup2bmytJysvLc1yhFfTdd9/pUsFF1es4WLV9b67wuKIfjuvC0e0qzDyh0qJLFR535Yeyq49zxncyrmaOc8Z3Mq5mjnPGdzKuZo67nrGFPyRLhmH67yUluf9T3lfrtGXLFrVo0cJUrbVq1VJpqfm/+FfncSkpKdf198Mb+d+vsrVe+c7vvvtO9evXN/Wd9nYlExiGcc1+FuO3eri4H374Qb/73e/02WefqXPnztb26OhoxcfHKyUlpcyYqKgozZ0790aWCQAAAKAKSU9PV+PGjcvdX+VnpK6wWCw224ZhlGm7YtasWZo2bZp1u7S0VD/99JP8/f3LHeMIeXl5CgkJUXp6uurVq3fDvhfVG9cVHIVrC47AdQVH4LrC9TAMQ+fPn1dwcPA1+1X5IBUQEKDatWsrMzPTpj0rK0uBgYFXHePp6VnmoTtnTiHWq1eP/8lhd1xXcBSuLTgC1xUcgesKleXr6/ubfWrdgDocysPDQx06dFBCQoJNe0JCgs2tfgAAAABgL1V+RkqSpk2bppEjR+quu+7Svffeq+XLlystLU3jx493dmkAAAAAqqFqEaSGDh2qs2fPat68ecrIyFDr1q318ccfq0mTJs4u7Zo8PT31/PPPV2ptf6A8XFdwFK4tOALXFRyB6wo3QpVftQ8AAAAAbrQq/4wUAAAAANxoBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSClBMtXbpUYWFh8vLyUocOHbRr1y5nlwQXFRUVJYvFYvMJCgqy7jcMQ1FRUQoODladOnXUvXt3HTlyxOYYhYWFevrppxUQEKC6detqwIAB+v7772/0qcCJdu7cqf79+ys4OFgWi0UbNmyw2W+v6ygnJ0cjR46Ur6+vfH19NXLkSJ07d87BZwdn+a3r6vHHHy/z8+uee+6x6cN1hV+LiYlRx44d5ePjo4YNG2rQoEFKSUmx6cPPLDgbQcpJ3n33XU2ZMkWzZ8/WgQMHdN9996lfv35KS0tzdmlwUa1atVJGRob1880331j3LViwQLGxsXrttdf01VdfKSgoSL1799b58+etfaZMmaL169dr7dq12r17t/Lz8xUREaGSkhJnnA6c4MKFC2rbtq1ee+21q+6313U0bNgwHTx4UJs3b9bmzZt18OBBjRw50uHnB+f4retKkh588EGbn18ff/yxzX6uK/xaYmKiJk6cqM8//1wJCQm6fPmy+vTpowsXLlj78DMLTmfAKe6++25j/PjxNm233XabMXPmTCdVBFf2/PPPG23btr3qvtLSUiMoKMh46aWXrG2XLl0yfH19jWXLlhmGYRjnzp0z3N3djbVr11r7nDlzxqhVq5axefNmh9YO1yTJWL9+vXXbXtfR0aNHDUnG559/bu2zd+9eQ5Jx7NgxB58VnO3X15VhGMaoUaOMgQMHljuG6woVkZWVZUgyEhMTDcPgZxZcAzNSTlBUVKSkpCT16dPHpr1Pnz7as2ePk6qCq/v2228VHByssLAwPfroozp16pQkKTU1VZmZmTbXk6enp7p162a9npKSklRcXGzTJzg4WK1bt+aagyT7XUd79+6Vr6+vOnXqZO1zzz33yNfXl2utBtuxY4caNmyo5s2b64knnlBWVpZ1H9cVKiI3N1eS5OfnJ4mfWXANBCknyM7OVklJiQIDA23aAwMDlZmZ6aSq4Mo6deqkVatWacuWLfrHP/6hzMxMde7cWWfPnrVeM9e6njIzM+Xh4aEGDRqU2wc1m72uo8zMTDVs2LDM8Rs2bMi1VkP169dPb7/9tj799FMtWrRIX331lR544AEVFhZK4rrCbzMMQ9OmTVPXrl3VunVrSfzMgmtwc3YBNZnFYrHZNgyjTBsg/fwXkSvatGmje++9V02bNlV8fLz1oe3KXE9cc/g1e1xHV+vPtVZzDR061Prr1q1b66677lKTJk300UcfafDgweWO47rCFU899ZQOHTqk3bt3l9nHzyw4EzNSThAQEKDatWuX+ZeOrKysMv+yAlxN3bp11aZNG3377bfW1fuudT0FBQWpqKhIOTk55fZBzWav6ygoKEg//vhjmeP/73//41qDJKlRo0Zq0qSJvv32W0lcV7i2p59+Wh9++KG2b9+uxo0bW9v5mQVXQJByAg8PD3Xo0EEJCQk27QkJCercubOTqkJVUlhYqOTkZDVq1EhhYWEKCgqyuZ6KioqUmJhovZ46dOggd3d3mz4ZGRk6fPgw1xwkyW7X0b333qvc3Fx9+eWX1j5ffPGFcnNzudYgSTp79qzS09PVqFEjSVxXuDrDMPTUU09p3bp1+vTTTxUWFmazn59ZcAlOWeICxtq1aw13d3djxYoVxtGjR40pU6YYdevWNb777jtnlwYXFBkZaezYscM4deqU8fnnnxsRERGGj4+P9Xp56aWXDF9fX2PdunXGN998Y/zpT38yGjVqZOTl5VmPMX78eKNx48bGtm3bjP379xsPPPCA0bZtW+Py5cvOOi3cYOfPnzcOHDhgHDhwwJBkxMbGGgcOHDBOnz5tGIb9rqMHH3zQuOOOO4y9e/cae/fuNdq0aWNERETc8PPFjXGt6+r8+fNGZGSksWfPHiM1NdXYvn27ce+99xq/+93vuK5wTX/5y18MX19fY8eOHUZGRob1c/HiRWsffmbB2QhSTvT6668bTZo0MTw8PIw777zTuqQn8GtDhw41GjVqZLi7uxvBwcHG4MGDjSNHjlj3l5aWGs8//7wRFBRkeHp6Gvfff7/xzTff2ByjoKDAeOqppww/Pz+jTp06RkREhJGWlnajTwVOtH37dkNSmc+oUaMMw7DfdXT27Flj+PDhho+Pj+Hj42MMHz7cyMnJuUFniRvtWtfVxYsXjT59+hg333yz4e7uboSGhhqjRo0qc81wXeHXrnZNSTJWrlxp7cPPLDibxTAM40bPggEAAABAVcYzUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgBUSY8//rgGDRpk9+NmZmaqd+/eqlu3rurXr2/3419LXFzcDf9OAEDlEKQAAOVyVFgx47vvvpPFYtHBgwdvyPe9/PLLysjI0MGDB3X8+PEb8p1XDB069IZ/JwCgctycXQAAAK7k5MmT6tChg8LDwys8pqioSB4eHtf93XXq1FGdOnWu+zgAAMdjRgoAUGlHjx7VQw89pJtuukmBgYEaOXKksrOzrfu7d++uSZMmacaMGfLz81NQUJCioqJsjnHs2DF17dpVXl5euv3227Vt2zZZLBZt2LBBkhQWFiZJat++vSwWi7p3724z/u9//7saNWokf39/TZw4UcXFxdes+Y033lDTpk3l4eGhFi1a6K233rLuu+WWW/TBBx9o1apVslgsevzxx696jCszdTExMQoODlbz5s0lSWfOnNHQoUPVoEED+fv7a+DAgfruu+8kSVu2bJGXl5fOnTtnc6xJkyapW7dukq5+a9/GjRvVoUMHeXl56dZbb9XcuXN1+fJlSVJkZKT69+9v7bt48WJZLBZ99NFH1rYWLVrozTfflCTt2LFDd999t/W2xS5duuj06dPX/P0CAFwdQQoAUCkZGRnq1q2b2rVrp3379mnz5s368ccfNWTIEJt+8fHxqlu3rr744gstWLBA8+bNU0JCgiSptLRUgwYNkre3t7744gstX75cs2fPthn/5ZdfSpK2bdumjIwMrVu3zrpv+/btOnnypLZv3674+HjFxcUpLi6u3JrXr1+vyZMnKzIyUocPH9a4ceM0evRobd++XZL01Vdf6cEHH9SQIUOUkZGhV155pdxjffLJJ0pOTlZCQoI2bdqkixcvqkePHrrpppu0c+dO7d69WzfddJMefPBBFRUVqVevXqpfv74++OAD6zFKSkr03nvvafjw4Vf9ji1btmjEiBGaNGmSjh49qjfffFNxcXF68cUXJf0cVHft2qXS0lJJUmJiogICApSYmCjp5+e9jh8/rm7duuny5csaNGiQunXrpkOHDmnv3r168sknZbFYyj1HAMA1GAAAlGPUqFHGwIEDr7rvueeeM/r06WPTlp6ebkgyUlJSDMMwjG7duhldu3a16dOxY0fj2WefNQzDMP773/8abm5uRkZGhnV/QkKCIclYv369YRiGkZqaakgyDhw4UKa2Jk2aGJcvX7a2/fGPfzSGDh1a7vl07tzZeOKJJ2za/vjHPxoPPfSQdXvgwIHGqFGjyj3Gle8ODAw0CgsLrW0rVqwwWrRoYZSWllrbCgsLjTp16hhbtmwxDMMwJk2aZDzwwAPW/Vu2bDE8PDyMn376yTAMw1i5cqXh6+tr3X/fffcZ0dHRNt/91ltvGY0aNTIMwzDOnTtn1KpVy9i3b59RWlpq+Pv7GzExMUbHjh0NwzCMNWvWGIGBgYZhGMbZs2cNScaOHTuueW4AgIphRgoAUClJSUnavn27brrpJuvntttuk/Tzc0ZX3HHHHTbjGjVqpKysLElSSkqKQkJCFBQUZN1/9913V7iGVq1aqXbt2lc99tUkJyerS5cuNm1dunRRcnJyhb/zijZt2tg8F5WUlKQTJ07Ix8fH+vvh5+enS5cuWX8/hg8frh07duiHH36QJL399tt66KGH1KBBg6t+R1JSkubNm2fze/zEE08oIyNDFy9elK+vr9q1a6cdO3bom2++Ua1atTRu3Dh9/fXXOn/+vHbs2GG9bdDPz0+PP/64+vbtq/79++uVV15RRkaG6fMGAPyMxSYAAJVSWlqq/v37a/78+WX2NWrUyPprd3d3m30Wi8V6K5phGNd1a9m1jl2eX39fZWuoW7euzXZpaak6dOigt99+u0zfm2++WdLPIbFp06Zau3at/vKXv2j9+vVauXJlud9RWlqquXPnavDgwWX2eXl5Sfr59r4dO3bIw8ND3bp1U4MGDdSqVSt99tln2rFjh6ZMmWIds3LlSk2aNEmbN2/Wu+++q//7v/9TQkKC7rnnHtPnDwA1HUEKAFApd955pz744APdcsstcnOr3B8nt912m9LS0vTjjz8qMDBQ0s/PKf3SlVmfkpKS6ytYUsuWLbV792499thj1rY9e/aoZcuW133sO++8U++++64aNmyoevXqldtv2LBhevvtt9W4cWPVqlVLDz/88DWPmZKSombNmpXbp3v37lqxYoXc3NzUq1cvSVK3bt20du1a6/NRv9S+fXu1b99es2bN0r333qs1a9YQpACgEri1DwBwTbm5uTp48KDNJy0tTRMnTtRPP/2kP/3pT/ryyy916tQpbd26VWPGjKlw6Ondu7eaNm2qUaNG6dChQ/rss8+si01cmSVq2LCh6tSpY13MIjc3t9Ln8swzzyguLk7Lli3Tt99+q9jYWK1bt07Tp0+v9DGvGD58uAICAjRw4EDt2rVLqampSkxM1OTJk/X999/b9Nu/f79efPFF/eEPf7DOLF3NnDlztGrVKkVFRenIkSNKTk62ziRdcf/99+v8+fPauHGjdUXD7t27a/Xq1br55pt1++23S5JSU1M1a9Ys7d27V6dPn9bWrVt1/Phxu4RIAKiJCFIAgGvasWOHdRbjymfOnDkKDg7WZ599ppKSEvXt21etW7fW5MmT5evrq1q1KvbHS+3atbVhwwbl5+erY8eO+vOf/2wNCVcChpubm1599VW9+eabCg4O1sCBAyt9LoMGDdIrr7yihQsXqlWrVnrzzTe1cuXKMkuqV4a3t7d27typ0NBQDR48WC1bttSYMWNUUFBgM0MVHh6ujh076tChQ+Wu1ndF3759tWnTJiUkJKhjx4665557FBsbqyZNmlj7+Pr6qn379vLz87OGpvvuu0+lpaU2s1He3t46duyYfv/736t58+Z68skn9dRTT2ncuHHXfe4AUBNZDMMwnF0EAABXfPbZZ+ratatOnDihpk2bOrscAACuiiAFAHCq9evX66abblJ4eLhOnDihyZMnq0GDBtq9e7ezSwMAoFwsNgEAcKrz589rxowZSk9PV0BAgHr16qVFixY5uywAAK6JGSkAAAAAMInFJgAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwKT/B+kZr6TmHotTAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show histogram of document length\n",
    "plt.figure(figsize = (10, 4))\n",
    "plt.hist(file_len_list, bins = 50, edgecolor = 'black')\n",
    "plt.xlabel('Length of reviews')\n",
    "plt.ylabel('Number of documents')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026c11eb-3c7e-4be0-9146-dd47c5f4e93f",
   "metadata": {},
   "source": [
    "vii. To represent each text (= data point), there are many ways. In NLP/Deep\n",
    "Learning terminology, this task is called tokenization. It is common to rep\u0002resent text using popularity/ rank of words in text. The most common word\n",
    "in the text will be represented as 1, the second most common word will be\n",
    "represented as 2, etc. Tokenize each text document using this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46dbd9a8-c078-4a52-ae02-3a9b1089be59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 1), ('a', 2), ('and', 3), ('of', 4), ('to', 5), ('is', 6), ('in', 7), ('that', 8), ('it', 9), ('as', 10), ('with', 11), ('for', 12), ('his', 13), ('this', 14), ('film', 15)]\n"
     ]
    }
   ],
   "source": [
    "word_indexes = t.word_index\n",
    "print(list(word_indexes.items())[:15])  # Show the 15 most frequent words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8936f3-4e57-4be6-b3ef-5fc64f7947f3",
   "metadata": {},
   "source": [
    "viii. Select a review length L that 70% of the reviews have a length below it. If\n",
    "you feel more adventurous, set the threshold to 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49b253b9-0218-4dcb-a4ee-f650401f0a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "737"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.copy()\n",
    "df1['Length'] = file_len_list\n",
    "df1_sorted = df1.sort_values(by = ['Length'], ascending=False)\n",
    "# df1_sorted\n",
    "\n",
    "# Select a review length L that 70% of the reviews have a length below it.\n",
    "len_threshold = 0.7\n",
    "L = (df1_sorted.iloc[[int(len(df1_sorted) * (1 - len_threshold))]])['Length'].values[0]\n",
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69efdd76-217f-4f20-9916-345f9d5b2267",
   "metadata": {},
   "source": [
    "ix. Truncate reviews longer than L words and zero-pad reviews shorter than L\n",
    "so that all texts (= data points) are of length L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53002844-1f31-41aa-ad42-d99918ba7547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 0],\n",
       "       [1, 2, 3, 4, 6],\n",
       "       [1, 2, 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def truncate_pad(X, L = 737):   # texts: the list of strings of texts. X in this case\n",
    "    # Reference: https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences\n",
    "    texts = list(X)\n",
    "    t = Tokenizer()  # Most common 50 words  # t = Tokenizer(num_words=5000)\n",
    "    t.fit_on_texts(texts)\n",
    "    sequences = t.texts_to_sequences(texts)  # Obtaining the sequence. Assisted by ChatGPT\n",
    "    sequences_padded = pad_sequences(sequences, maxlen = L, truncating = 'post', padding = 'post')   # footnote 3\n",
    "    return sequences_padded\n",
    "\n",
    "# Test\n",
    "Test_text = [\n",
    "    \"hi im saul goodman\",\n",
    "    \"hi im saul goodman did you know that you have rights\",\n",
    "    \"hi im\"\n",
    "]\n",
    "truncate_pad(Test_text, L = 5)   # Each list is its own document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65ba53a8-f89f-463a-a15a-4b907c06216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad = truncate_pad(X_train)\n",
    "X_test_pad = truncate_pad(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc8decb-3f9d-4037-a4cb-e1bdaf58df71",
   "metadata": {},
   "source": [
    "### (c) Word Embeddings\n",
    "\n",
    "i. Assume that we are inter\u0002ested in the top 5,000 words. This means that in each integer sequence that\n",
    "represents each document, we set to zero those integers that represent words\n",
    "that are not among the top 5,000 words in the document.\n",
    "Choose the length\n",
    "of the embedding vector for each word to be 32. Hence, each document is\n",
    "represented as a 32 × L matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58ca8e0f-21bb-4158-9393-17b4b1f50ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13352\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Kera sequential model \n",
    "# Reference: https://www.tensorflow.org/text/guide/word_embeddings\n",
    "            #https://www.tensorflow.org/guide/keras/sequential_model\n",
    "            #https://keras.io/api/layers/core_layers/embedding/\n",
    "model = Sequential()    \n",
    "model.add(Embedding(input_dim=5000+1, output_dim=32, input_length=L))   # L = 737"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03741813-fd29-470b-8210-af5643051e99",
   "metadata": {},
   "source": [
    "ii. Flatten the matrix of each document to a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb3418fb-ca1f-4c05-8610-0f4a3874fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cfe728-0a22-4958-b649-1cd4714fa228",
   "metadata": {},
   "source": [
    "### (d) Multi-Layer Perceptron\n",
    "\n",
    "i. Train a MLP with three (dense) hidden layers each of which has 50 ReLUs\n",
    "and one output layer with a single sigmoid neuron. Use a dropout rate of\n",
    "20% for the first layer and 50% for the other layers. Use ADAM optimizer\n",
    "and binary cross entropy loss (which is equivalent to having a softmax in the\n",
    "output). To avoid overfitting, just set the number of epochs as 2. Use a batch\n",
    "size of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "087222f3-06d5-4692-a914-bfcb9c928b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.tensorflow.org/guide/keras/sequential_model\n",
    "# https://keras.io/guides/sequential_model/\n",
    "# https://www.youtube.com/watch?v=kyktbJpg2mU Keras sequential video tutorial by Dr. Data Science\n",
    "\n",
    "# Build the 3-layer perceptron model using sigmoid activation function\n",
    "model.add(Dense(50, activation=\"relu\", name = 'hidden_layer1'))\n",
    "model.add(Dropout(0.2))   # Dropout is a regularization. Drop 20% of the neurons\n",
    "model.add(Dense(50, activation=\"relu\", name = 'hidden_layer2'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation=\"relu\", name = 'hidden_layer3'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation=\"sigmoid\", name = 'output_layer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88e1dcc7-ed71-4975-97b6-35639f52ecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb3b0a05-a971-4e88-be3b-ccb80c82d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the words with index above 5000 to 0\n",
    "X_train_pad[X_train_pad > 5000] = 0\n",
    "#X_train_pad = np.array(X_train_pad)\n",
    "X_test_pad[X_test_pad > 5000] = 0\n",
    "#X_test_pad = np.array(X_test_pad)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3ea148b-57c6-4724-9418-510fa6c5571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need to hand-pick some words that doesn't contribute to the sentiments. \n",
    "#print(word_indexes)\n",
    "def drop_words(X_pad):\n",
    "    moodless_words = ['the', 'a', 'and', 'of', 'to', 'is', 'in', 'that', 'as', 'with', 'this', 'on', 'are', 'by', 'be', 'movie', \n",
    "                      'we', 'it', 'i', 'his', 'her', 'he', 'she', 'film']\n",
    "    # Add words if needed\n",
    "    moodless_index_list = [word_indexes[word] for word in moodless_words if word in word_indexes]\n",
    "    for i, sequence in enumerate(X_pad):   # enumerate: turn list into indexed lists. Assisted by ChatGPT\n",
    "        for j, word_index in enumerate(sequence):\n",
    "            if word_index in moodless_index_list:\n",
    "                X_pad[i][j] = 0\n",
    "    return X_pad\n",
    "X_train_pad = drop_words(X_train_pad)\n",
    "X_test_pad = drop_words(X_test_pad)\n",
    "# X_test_pad[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e78aef0-071e-4dd6-b022-83da2f1691c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4454 - loss: 0.7081\n",
      "Epoch 2/2\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5312 - loss: 0.6925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/model.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train_pad, y_train, epochs = 2, batch_size = 10)  # X_train_pad should be a padded sequence matrix\n",
    "\n",
    "# Save the model\n",
    "dump(model, '../models/model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22399425-eb18-4bc0-9c99-c0b10c9fab1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">737</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">160,032</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23584</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,250</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m737\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │       \u001b[38;5;34m160,032\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m23584\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │     \u001b[38;5;34m1,179,250\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │         \u001b[38;5;34m2,550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │         \u001b[38;5;34m2,550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)                │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,033,301</span> (15.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,033,301\u001b[0m (15.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,344,433</span> (5.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,344,433\u001b[0m (5.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,688,868</span> (10.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,688,868\u001b[0m (10.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the model from local files\n",
    "model = load('../models/model.joblib')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eccb99f-ede4-4370-8ca9-6f08ab152444",
   "metadata": {},
   "source": [
    "ii. Report the train and test accuracies of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4e52101-b9b6-4a16-ad45-51b08fb66378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8147 - loss: 0.6300 \n",
      "Train Accuracy: 0.7685714364051819\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6046 - loss: 0.6803 \n",
      "Test Accuracy: 0.5383333563804626\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_accuracy = model.evaluate(X_train_pad, y_train)\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "\n",
    "# Evaluate the model on testing data\n",
    "test_loss, test_accuracy = model.evaluate(X_test_pad, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641dbf6f-9356-4168-8e48-239e910e14f7",
   "metadata": {},
   "source": [
    "### (e) One-Dimensional Convolutional Neural Network:\n",
    "\n",
    "Although CNNs are mainly used for image data, they can also be applied to text\n",
    "data, as text also has adjacency information. Keras supports one-dimensional\n",
    "convolutions and pooling by the Conv1D and MaxPooling1D classes respectively.\n",
    "\n",
    "i. After the embedding layer, insert a Conv1D layer. This convolutional layer\n",
    "has 32 feature maps , and each of the 32 kernels has size 3, i.e. reads embedded\n",
    "word representations 3 vector elements of the word embedding at a time. The\n",
    "convolutional layer is followed by a 1D max pooling layer with a length and\n",
    "stride of 2 that halves the size of the feature maps from the convolutional\n",
    "layer. The rest of the network is the same as the neural network above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2eca3fcc-670f-46f5-94fa-233751347e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13352\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5051 - loss: 0.6973\n",
      "Epoch 2/2\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5600 - loss: 0.6865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/model1.joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reonstruct the model \n",
    "model1 = Sequential([\n",
    "    Embedding(input_dim=5000+1, output_dim=32, input_length=L),\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu'),  \n",
    "        # Reference: https://keras.io/api/layers/convolution_layers/convolution1d/\n",
    "        # Reference: https://stackoverflow.com/questions/69591717/how-is-the-keras-conv1d-input-specified-i-seem-to-be-lacking-a-dimension answer by AloneTogether\n",
    "    MaxPooling1D(pool_size=2, strides=2),\n",
    "        # Reference: https://keras.io/api/layers/pooling_layers/max_pooling1d/\n",
    "    Flatten(),\n",
    "    Dense(50, activation='relu', name = 'hidden_layer1'),\n",
    "    Dropout(0.2),  # 20% dropout\n",
    "    Dense(50, activation='relu', name = 'hidden_layer2'),\n",
    "    Dropout(0.5),  # 50% dropout\n",
    "    Dense(50, activation='relu', name = 'hidden_layer3'),\n",
    "    Dropout(0.5),  # 50% dropout\n",
    "    Dense(1, activation='sigmoid', name = 'output_layer')\n",
    "])\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model1.fit(X_train_pad, y_train, epochs = 2, batch_size = 10)   # Too high of epochs can overfit (100% train acc but 50% test acc)\n",
    "\n",
    "# Save the model\n",
    "dump(model1, '../models/model1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1888496f-5aac-4878-a5c5-873ca7a3b006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">737</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">160,032</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">735</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">367</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11744</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">587,250</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m737\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │       \u001b[38;5;34m160,032\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m735\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │         \u001b[38;5;34m3,104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m367\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m11744\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │       \u001b[38;5;34m587,250\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │         \u001b[38;5;34m2,550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │         \u001b[38;5;34m2,550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)                │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,266,613</span> (8.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,266,613\u001b[0m (8.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">755,537</span> (2.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m755,537\u001b[0m (2.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,511,076</span> (5.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,511,076\u001b[0m (5.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the model\n",
    "model1 = load('../models/model1.joblib')\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7cf966-7616-4c31-9672-44f4b10f0d85",
   "metadata": {},
   "source": [
    "ii. Report the train and test accuracies of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b26a81e8-65c5-46d8-910a-9ced299f331e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7383 - loss: 0.6095 \n",
      "Train Accuracy: 0.7021428346633911\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6145 - loss: 0.6580 \n",
      "Test Accuracy: 0.54666668176651\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_accuracy = model1.evaluate(X_train_pad, y_train)\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "\n",
    "# Evaluate the model on testing data\n",
    "test_loss, test_accuracy = model1.evaluate(X_test_pad, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eedec44-d5b7-4bee-9304-22e29efbe494",
   "metadata": {},
   "source": [
    "### (f) Long Short-Term Memory Recurrent Neural Network\n",
    "\n",
    "The structure of the LSTM we are going to use is shown in the following figure\n",
    "\n",
    "i. Each word is represented to LSTM as a vector of 32 elements and the LSTM\n",
    "is followed by a dense layer of 256 ReLUs. Use a dropout rate of 0.2 for both LSTM and the dense layer. Train the model using 10-50 epochs and batch\n",
    "size of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39a31643-cbf4-47ec-8e76-6fc11ccf4324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13352\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 83ms/step - accuracy: 0.5043 - loss: 0.6934\n",
      "Epoch 2/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 82ms/step - accuracy: 0.5126 - loss: 0.6907\n",
      "Epoch 3/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 83ms/step - accuracy: 0.5924 - loss: 0.6889\n",
      "Epoch 4/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 84ms/step - accuracy: 0.6401 - loss: 0.5966\n",
      "Epoch 5/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 84ms/step - accuracy: 0.6553 - loss: 0.5653\n",
      "Epoch 6/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 83ms/step - accuracy: 0.6689 - loss: 0.5316\n",
      "Epoch 7/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 84ms/step - accuracy: 0.6739 - loss: 0.5165\n",
      "Epoch 8/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 84ms/step - accuracy: 0.6715 - loss: 0.4857\n",
      "Epoch 9/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 85ms/step - accuracy: 0.7001 - loss: 0.4726\n",
      "Epoch 10/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 83ms/step - accuracy: 0.6740 - loss: 0.5339\n",
      "Epoch 11/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 85ms/step - accuracy: 0.6782 - loss: 0.4741\n",
      "Epoch 12/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 87ms/step - accuracy: 0.6813 - loss: 0.4735\n",
      "Epoch 13/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 86ms/step - accuracy: 0.6988 - loss: 0.4624\n",
      "Epoch 14/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 85ms/step - accuracy: 0.6440 - loss: 0.4750\n",
      "Epoch 15/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 86ms/step - accuracy: 0.6981 - loss: 0.4754\n",
      "Epoch 16/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 94ms/step - accuracy: 0.6531 - loss: 0.5348\n",
      "Epoch 17/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 88ms/step - accuracy: 0.6607 - loss: 0.4964\n",
      "Epoch 18/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 91ms/step - accuracy: 0.6689 - loss: 0.4904\n",
      "Epoch 19/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 88ms/step - accuracy: 0.6725 - loss: 0.4764\n",
      "Epoch 20/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - accuracy: 0.6873 - loss: 0.4831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22e05725e50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference: https://www.youtube.com/watch?v=wY0dyFgNCgY LSTM video by Jeff Heaton\n",
    "# https://keras.io/api/layers/recurrent_layers/lstm/\n",
    "# https://towardsdatascience.com/a-practical-guide-to-rnn-and-lstm-in-keras-980f176271bc\n",
    "\n",
    "LSTM_model = Sequential([\n",
    "    Embedding(input_dim = 5000 + 1, output_dim = 32, input_length = L),\n",
    "    #Flatten(),\n",
    "    LSTM(32),\n",
    "    Dropout(0.2),\n",
    "    Dense(256, activation = 'relu', name = 'dense_layer'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation = 'sigmoid', name = 'output_layer')\n",
    "])\n",
    "LSTM_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "LSTM_model.fit(X_train_pad, y_train, epochs = 20, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b900d9-892e-4a2d-86a2-d23088e9f158",
   "metadata": {},
   "source": [
    "ii. Report the train and test accuracies of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4fcb52d-f475-41da-9053-803c703e5bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/LSTM_model.joblib']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "dump(LSTM_model, '../models/LSTM_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ddd7b65-29ee-43f4-beda-0ed0d0ba7e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">737</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">160,032</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m737\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │       \u001b[38;5;34m160,032\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │         \u001b[38;5;34m8,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)                │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">531,173</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m531,173\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">177,057</span> (691.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m177,057\u001b[0m (691.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">354,116</span> (1.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m354,116\u001b[0m (1.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load back the models \n",
    "LSTM_model = load('../models/LSTM_model.joblib')\n",
    "LSTM_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc7efcff-1386-4bad-900d-45fb74b7d593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.4630 - loss: 0.4817\n",
      "Train Accuracy: 0.6821428537368774\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.3416 - loss: 1.1962\n",
      "Test Accuracy: 0.5249999761581421\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_accuracy = LSTM_model.evaluate(X_train_pad, y_train)\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "\n",
    "# Evaluate the model on testing data\n",
    "test_loss, test_accuracy = LSTM_model.evaluate(X_test_pad, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38de39bf-42cd-4093-856d-459d94a6f3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13352\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 91ms/step - accuracy: 0.4824 - loss: 0.6938\n",
      "Epoch 2/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 91ms/step - accuracy: 0.5122 - loss: 0.6925\n",
      "Epoch 3/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 89ms/step - accuracy: 0.6137 - loss: 0.6297\n",
      "Epoch 4/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 93ms/step - accuracy: 0.6720 - loss: 0.5611\n",
      "Epoch 5/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 95ms/step - accuracy: 0.6782 - loss: 0.5277\n",
      "Epoch 6/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 94ms/step - accuracy: 0.6834 - loss: 0.4906\n",
      "Epoch 7/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - accuracy: 0.6920 - loss: 0.4828\n",
      "Epoch 8/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 92ms/step - accuracy: 0.6817 - loss: 0.4718\n",
      "Epoch 9/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 91ms/step - accuracy: 0.6850 - loss: 0.4619\n",
      "Epoch 10/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 95ms/step - accuracy: 0.6908 - loss: 0.4575\n",
      "Epoch 11/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 94ms/step - accuracy: 0.7001 - loss: 0.4613\n",
      "Epoch 12/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 94ms/step - accuracy: 0.6832 - loss: 0.4877\n",
      "Epoch 13/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 96ms/step - accuracy: 0.6760 - loss: 0.4640\n",
      "Epoch 14/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 93ms/step - accuracy: 0.7032 - loss: 0.4869\n",
      "Epoch 15/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 93ms/step - accuracy: 0.7026 - loss: 0.4587\n",
      "Epoch 16/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 95ms/step - accuracy: 0.6785 - loss: 0.4734\n",
      "Epoch 17/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - accuracy: 0.7208 - loss: 0.4462\n",
      "Epoch 18/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 91ms/step - accuracy: 0.7104 - loss: 0.4513\n",
      "Epoch 19/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - accuracy: 0.6979 - loss: 0.4795\n",
      "Epoch 20/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 89ms/step - accuracy: 0.6660 - loss: 0.4723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/LSTM_model2.joblib']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM but with more layers to see if accuracy improves:\n",
    "LSTM_model2 = Sequential([\n",
    "    Embedding(input_dim = 5000 + 1, output_dim = 32, input_length = L),\n",
    "    #Flatten(),\n",
    "    LSTM(32),\n",
    "    Dropout(0.2),\n",
    "    Dense(256, activation = 'relu', name = 'dense_layer'),\n",
    "    Dropout(0.2),\n",
    "    Dense(256, activation = 'relu', name = 'dense_layer2'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation = 'sigmoid', name = 'output_layer')\n",
    "])\n",
    "LSTM_model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "LSTM_model2.fit(X_train_pad, y_train, epochs = 20, batch_size = 10)\n",
    "# Save the model\n",
    "dump(LSTM_model2, '../models/LSTM_model2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c8fb554-0d39-459d-82a9-b1ad6d8de024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.4720 - loss: 0.4980\n",
      "Train Accuracy: 0.6892856955528259\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.3523 - loss: 1.4368\n",
      "Test Accuracy: 0.5216666460037231\n"
     ]
    }
   ],
   "source": [
    "LSTM_model2 = load('../models/LSTM_model2.joblib')   # This is a model with 2 layers (for experiment to see if accuracy improves)\n",
    "train_loss, train_accuracy = LSTM_model2.evaluate(X_train_pad, y_train)\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "\n",
    "# Evaluate the model on testing data\n",
    "test_loss, test_accuracy = LSTM_model2.evaluate(X_test_pad, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# The accurarcy didnt improve significantly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a931aac-ab19-4796-8402-b0bdfcc1c5b7",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "* keras.io\n",
    "* https://www.tensorflow.org/\n",
    "* Pad Sequence documentation: https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences\n",
    "* https://www.tensorflow.org/guide/keras/sequential_model\n",
    "* Word Embedding documentation: https://www.tensorflow.org/text/guide/word_embeddings\n",
    "* https://www.youtube.com/watch?v=kyktbJpg2mU Keras sequential video tutorial by Dr. Data Science\n",
    "* https://keras.io/api/layers/core_layers/embedding/\n",
    "* Convolution documentation: https://keras.io/api/layers/convolution_layers/convolution1d/\n",
    "* Convolution reference https://stackoverflow.com/questions/69591717/how-is-the-keras-conv1d-input-specified-i-seem-to-be-lacking-a-dimension by AloneTogether\n",
    "* Max pooling id: https://keras.io/api/layers/pooling_layers/max_pooling1d/\n",
    "* LSTM https://www.youtube.com/watch?v=wY0dyFgNCgY LSTM video by Jeff Heaton\n",
    "* LSTM documentation https://keras.io/api/layers/recurrent_layers/lstm/\n",
    "* LSTM reference: https://towardsdatascience.com/a-practical-guide-to-rnn-and-lstm-in-keras-980f176271bc\n",
    "* ChatGPT by OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7307fc-9c7d-4ab4-9473-022488c295a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
